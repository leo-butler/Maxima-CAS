#!/usr/bin/perl -s
use warnings;
use strict;
use Data::Dumper;
use vars qw($main_info $encoding $info_files);
use open 'IN' => ':bytes';
require 5.8.0;

=pod

=head1 build_index.pl

A Perl script to construct Maxima's online help from its TeXinfo
documentation.

=head1 SYNOPSIS

Builds LISP code that defines two hashes, *info-deffn-defvr-pairs* and
*info-section-pairs*, used by Maxima's online help system in
src/cl-info.lisp. The code is written to STDOUT. An option is provided
to dump and reload the state of the Perl hash. This is useful for
de-bugging.

=head2 Sample calls:

=over 20

=item build_index.pl info-file encoding

The defaults are 'maxima.info' and ':crlf', respectively.

=item build_index.pl -main_info=B<maxima.info> -encoding=B<encoding>

Use named options.

=item build_index.pl -dump_pl_out=B<dump_file>

Dump the Perl hash to B<dump_file>.

=item build_index.pl -dump_pl_in=B<dump_file>

Read in the Perl hash from B<dump_file>.

=item build_index.pl -dump_pl_in=B<dump_file_in> -dump_pl_out=B<dump_file_out>

Read in a hash, and dump a new one.

=back

=head1 DESCRIPTION

This script does the following:

=head2 PART 1. BUILD INDEX FOR C<@DEFFN> AND C<@DEFVR> ITEMS

=over 5

=item (1.1) Build index tables.

=over 1

=item (1.1a)
Slurp the main info file, then slurp the remaining *.info-*
files (B<get_info_files>). Saved in the B<%info_files> hash.

=item (1.1b)
Scan the *.info-* files for unit separator characters;
those mark the start of each texinfo node.
Build a hash table which associates the node name with the filename
and byte offset (NOT character offset) of the unit separator.
Done in B<get_node_offsets>, results are saved in B<%info_files> hash.

Do NOT use the indirect table + tag table (generated by makeinfo),
because those tables give character offsets; we want byte offsets.
It is easier to construct a byte offset table by hand,
rather than attempting to fix up the character offsets.
(Which are strange anyway.)

=back

=item (1.2) Build index of topics.

=over 1

=item (1.2a)
For each indexed item in info files, translate node name
and number of lines offset into file name and byte offset for each
indexed item. Done in B<get_index_topics>.

=item (1.2b)
Also find the length and byte offsets of each indexed
item. This is done in B<get_byte_offsets_for_topics>.

=back

=back

=head2 PART 2. BUILD INDEX FOR C<@NODE> ITEMS

=over 5

=item (2.1)  Search for 'mmm.nnn' at the start of a line,
and take each one of those to be the start of a node.

        We could use the node table ($node_offset here), but we don't.

        (a) The node table indexes nodes which contain only menus.
            We don't want those because they have no useful text.

        (b) The offset stated in the node table tells the location
            of the "File: ..." header. We would have to cut off that stuff.

        (c) Offsets computed by makeinfo are character offsets,
            so we would have to convert those to byte offsets.
            (But we have to do that anyway, so I guess there's no
            advantage either way on that point.)

This work is done simultaneously in B<get_node_items_and_offsets>.

=item (2.2 optional) Dump the state of the Perl hash.

=back

=head2 PART 3. GENERATE LISP CODE.

=over 5

=item The functions in cl-info.lisp expect this stuff. The work is
done in B<write_lisp_code>, and the Lisp code is written to STDOUT.

=back

=head1 AUTHORS

Leo Butler    L<leo.butler@member.ams.org>

Robert Dodier

=head1 BUGS

Probably.

=head1 REQUIRES

Perl v 5.8.0 (to permit strings to be opened as files).

=head1 LICENSE

Same as the MAXIMA License. See L<http://maxima.sourceforge.net>.

=head1 SUBROUTINE DOCUMENTATION

=cut


sub slurp(@);
sub get_info_files(@);
sub get_node_offsets(@);
sub get_index_topics(@);
sub get_byte_offsets_for_topics(@);
sub get_node_items_and_offsets(@);
sub seek_lines(@);
sub write_lisp_code($);

our $main_info ||= shift || 'maxima.info';
our $encoding  ||= shift || ':crlf';
our $readmode  ||= "<$encoding";
our $bytemode  ||= '<';
our $separator ||= "\037";      ##""
our $del       ||= "\177";      ##""
our $dump_pl_in||= undef;
our $dump_pl_out||= undef;

our $file_node_re=qr/^File:.*?Node: (.*?),/osm;
our $separator_re=qr/\G.*?(?=\n$separator)/sm;
our $file_node_item_re=qr/^File:.*?Node: .+/oism; # .+ == $index_node_name
our $menu_item_re=qr/(.+?):\s+(.+)\.\s+.line\s+(\d+)/osm;
our $info_item_re=qr/(.*?)(?:\n\n(?= -- )|\n(?=[0-9])|(?=$separator))/osm;
our $node_item_re=qr/(.*?)(?=^\d+\.\d+ .*?\n)/osm;
our $node_title_re=qr/((^\d+\.\d+) (.*?)\n)/osm;
our $appendix_re =qr/\000\010\[index\000\010\]/osm;
our %info_files;
binmode STDOUT, $encoding;


MAIN:
{
   if (not $dump_pl_in) {
      get_info_files \%info_files,$main_info;
      get_node_offsets \%info_files,$separator_re,$file_node_re;
      get_index_topics \%info_files,$file_node_item_re,$menu_item_re,$appendix_re;
      get_byte_offsets_for_topics \%info_files,$info_item_re;
      get_node_items_and_offsets \%info_files,$node_item_re,$node_title_re;
   } elsif ($dump_pl_in and -r $dump_pl_in) {
      eval { do $dump_pl_in };
      die "$@" if $@;
      %info_files=%$info_files;
   }
   write_lisp_code \%info_files;
   dump_pl( \%info_files, $dump_pl_out ) if $dump_pl_out;
   exit 0;
}

sub slurp(@)
{
   my ($filename,$readmode)=@_;
   $readmode ||= $main::readmode;
   local $/=undef;
   open my $fh, $readmode, $filename or do { warn "Unable to open $filename, $!" and return "";};
   my $contents=<$fh>;
   close $fh;
   return $contents;
}

=pod

=over 5

=item B<get_info_files( \%info_files, $main_info )>

Slurps the main info file named by C<$main_info>, splits it at \037
bytes, extracts the other info names, then slurps these remaining
files. All contents are stored in C<%info_files>

=back


=cut

sub get_info_files(@)
{
   my ($info_files,$main_info)=@_;
   my $contents=slurp $main_info;
   $info_files->{$main_info}->{'contents'}=$contents;
   my @sections=split(/$main::separator/,$contents);
   my @filenames=grep { /$main_info/ } split( /:|\n/, $sections[1] );
   foreach (@filenames) {
      $info_files->{$_}->{'contents'}=slurp $_;
   }
   push @filenames, $main_info;
   @{$info_files->{'filenames'}}=sort @filenames;
   return %$info_files;
}

=pod

=over 5

=item B<get_node_offsets( \%info_files, $separator_re, $file_node_re )>

Looks for occurences of $separator, records its position as an offset,
and then records occurences of info Nodes. Morally, C<$separator_re> is
\037.

=back

=cut

sub get_node_offsets(@)
{
   my ($info_files,$separator_re,$file_node_re)=@_;
   my @filenames=@{$info_files->{'filenames'}};
   #print Dumper(@filenames);
   my ($node_name,$offset);
   foreach my $file (@filenames) {
      my $contents=$info_files->{$file}->{'contents'};
      while ($contents =~ m/$separator_re/cg) {
         $offset = pos $contents;
         if ($contents =~ m/$file_node_re/cg) {
            $node_name = $1;
            # print ";; IN SEC 1.1a, SEARCH SUBSIDIARY INFO; NODE NAME=$node_name, FILENAME=$filename, OFFSET=$offset\n";
            $info_files->{$file}->{'nodes'}->{$node_name}=int($offset);
         }
      }
   }
   return %$info_files;
}

=pod

=over 5

=item B<get_index_topics( \%info_files,$file_node_re,$menu_item_re,$appendix_re )>

Scans the final info file for appendix/topic nodes. The node name and
line offset are indexed by the topic name in the 'topics' hash inside
C<%info_files>.

=back

=cut

sub get_index_topics(@)
{
   my ($info_files,$file_node_re,$menu_item_re,$appendix_re)=@_;
   my $index_file=$info_files->{'filenames'}[-1];
   my $contents=$info_files->{$index_file}->{'contents'};
   my $topic_locator;
   while ($contents =~ m/$file_node_re/cg) {
      my @contents=grep { /$appendix_re/ } split(/$main::separator/,$contents);
      my @appendix=grep { /line/ } split(/^\*\s*/sm,$contents[-1]);
      foreach (@appendix) {
	 if (/$menu_item_re/cg) {
	    my $topic_name = $1;
	    my $node_name = $2;
	    my $lines_offset = $3;
	    # print ";; IN SEC 1.1b, TOPIC NAME=$topic_name, NODE NAME=$node_name, LINES OFFSET=$lines_offset\n";
	    $topic_locator->{$topic_name} = [($node_name, $lines_offset)];
	 }
      }
   }
   $info_files->{'topics'}=$topic_locator;
   return %$info_files;
}

=pod

=over 5

=item B<get_byte_offsets_for_topics( \%info_files,$info_item_re )>

For each topic in 'topics', we determine the byte offset and length of
that topic item. This requires numerous reads from the info files,
which we accomplish by opening their contents in the C<%info_files>
hash as filehandles.

=back

=cut

sub get_byte_offsets_for_topics(@)
{
   my ($info_files,$info_item_re)=@_;
   my %topics=%{$info_files->{'topics'}};
   my $filenames=$info_files->{'filenames'};
   my $node_offset=sub {
      my $node_name=shift;
      my $node_offset;
      my @node_offset;
      foreach my $filename (@$filenames) {
	 $node_offset=$info_files->{$filename}->{'nodes'}->{$node_name};
	 #print $filename, $node_name, ($node_offset) ? $node_offset : '',"\n";
	 if ($node_offset) {
	    push @node_offset,$filename,$node_offset;
	    last;
	 }
      }
      return @node_offset;
   };
   my $open_strings_as_files=sub {
      my $files=$info_files->{'filenames'};
      use bytes;
      foreach my $file (@$files) {
	 my $contents=$info_files->{$file}->{'contents'};
	 open my $fh, $main::bytemode, \$contents or die "$!";
	 $info_files->{$file}->{'filehandle'}=$fh;
      }
      return %$info_files;
   };
   $open_strings_as_files->();
   foreach my $topic (sort keys %topics) {
      my ($node_name,$lines_offset) = @{$topics{$topic}};
      my ($filename, $character_offset) = $node_offset->($node_name);
      #print $filename,$character_offset; die;
      my $byte_offset = seek_lines $info_files, $filename, $character_offset, $lines_offset ;
      my ($contents,$text_length);

      *FH=$info_files->{$filename}->{'filehandle'};
      seek FH, 0, 0;
      seek FH, $byte_offset, 0;
      {
	 local $/=undef;
	 $contents=<FH>;
      }
      if ($contents =~ m/$info_item_re/cgsm) {
      	 $text_length = length $1;
      } else {
      	 # Eat everything up til end of file.
      	 $contents =~ m/(.*)/cgsm;
      	 $text_length = length $1;
      }
      #$topic =~ /^expand$/ and print STDERR substr($contents,0,$text_length);
      # # print ";; IN SEC 1.2, KEY=$topic, NODE NAME=$node_name, FILENAME=$filename, BYTE OFFSET=$byte_offset, TEXT LENGTH=$text_length\n";
      $topics{$topic} = [($node_name, $filename, $byte_offset, $text_length)];
   }
   $info_files->{'topics'}=\%topics;
   return %$info_files;
}

=pod

=over 5

=item B<get_node_items_and_offsets( \%info_files,$node_item_re,$node_title_re )>

Scans each info file for info items and computes their byte offsets
and lengths. Again, we open the info file contents in memory (as a
character string/file), and use the C<tell> function to give the byte
offset of each item. The results are stored in the 'items' hash in
C<%info_files>.

=back

=cut

sub get_node_items_and_offsets(@)
{
   my ($info_files,$node_item_re,$node_title_re)=@_;
   my $filenames=$info_files->{'filenames'};
   my %items;
   for my $filename (@$filenames) {
      my $contents=$info_files->{$filename}->{'contents'};
      open FH, '<', \$contents or die "$!";
      seek FH, 0, 0;
      while ($contents =~ m/\G(.*?)(?=^\d+\.\d+ .*?\n)/cgsm) {

	 # Since FH was opened with $infofile_encoding,
	 # pos returns a CHARACTER offset.
	 my $begin_node_offset = pos($contents);
	 seek FH, 0, 0;
	 read FH, my($stuff), $begin_node_offset;
	 my $begin_node_offset_bytes = tell FH;

	 my ($node_title,$node_length);
	 if ($contents =~ m/((^\d+\.\d+) (.*?)\n)/cgsm) {
            $node_title = $3;
            $node_length = length $1;
	 }

	 # Node text ends at a unit separator character,
	 # or at the end of the file.
	 if ($contents =~ m/\G(.*?)(${main::separator})/cgsm) {
            $node_length += length $1;
	 } else {
            $contents =~ m/\G(.*)/csgm;
            $node_length += length $1;
	 }
	 $items{$node_title} = [($filename, $begin_node_offset_bytes, $node_length)];
      }
   }
   $info_files->{'items'}=\%items;
   return %$info_files;
}

=pod

=over 5

=item B<write_lisp_code( \%info_files )>

The 'topics' hash in C<%info_files> is written out to create the
C<*info-deffn-defvr-pairs*> Lisp list. The 'items' hash in
C<%info_files> is written out to create the C<*info-section-pairs*>
Lisp list.

=back

=cut

sub write_lisp_code($)
{
   my $info_files=shift;
   my $topics=$info_files->{'topics'};
   my $items=$info_files->{'items'};
   # Generate Lisp code expected in cl-info.lisp.
   print "(in-package :cl-info)\n";
   print "(defun cause-maxima-index-to-load () nil)\n";
   # Pairs of the form (<index topic> . (<filename> <byte offset> <length> <node name>))
   print "(defparameter *info-deffn-defvr-pairs* '(\n";
   print "; CONTENT: (<INDEX TOPIC> . (<FILENAME> <BYTE OFFSET> <LENGTH IN CHARACTERS> <NODE NAME>))\n";
   foreach my $topic (sort keys %$topics) {
      my ($section, $filename, $begin_node_offset, $length) = @{$topics->{$topic}};
      print '("', $topic, '" . ("', $filename, '" ', $begin_node_offset, ' ', $length, ' "', $section, '"))', "\n";
   }
   print "))\n";

   print "(defparameter *info-section-pairs* '(\n";
   print "; CONTENT: (<NODE NAME> . (<FILENAME> <BYTE OFFSET> <LENGTH IN CHARACTERS>))\n";
   foreach my $node_title (sort keys %$items) {
      my ($filename, $begin_node_offset, $length) = @{$items->{$node_title}};
      print '("', $node_title, '" . ("', $filename, '" ', $begin_node_offset, ' ', $length, '))', "\n";
   }
   print "))\n";
   print "(load-info-hashtables)\n";
   %$topics || %$items ||
   print STDERR "WARNING: Empty index. Probably makeinfo is too old. Version 4.7 or 4.8 required.\n";
}

sub dump_pl
{
   my ($info_files,$outfile)=@_;
   open my $fh, '>', $outfile or warn "Unable to dump to $outfile\n" and return 0;
   print $fh Data::Dumper->Dump([$info_files],[qw(main::info_files)]);
   close $fh;
   return 1;
}

sub seek_lines(@)
{
   my ($info_files, $filename, $character_offset, $lines_offset) = @_;
   my ($contents,$x);
   use bytes;
   *FH=$info_files->{$filename}->{'filehandle'};
   seek FH, 0, 0;
   read FH, $contents, $character_offset;

   # MAKEINFO BUG: LINE OFFSET IS LINE NUMBER OF LAST LINE IN FUNCTION DEFINITION
   # (BUT WE NEED THE FIRST LINE OF THE FUNCTION DEFINITION)
   # BUG IS PRESENT IN MAKEINFO 4.8; FOLLOWING CAN GO AWAY WHEN BUG IS FIXED

   for (1 .. $lines_offset + 1) {
      my $x_maybe = tell FH;
      my $line = <FH>;
      if ($line and $line =~ /^ -- \S/) {
	 $x = $x_maybe;
      } elsif (!$line) {
	 print $contents,"\n",$lines_offset;
	 die;
      }
   }

   # END OF MAKEINFO BUG WORKAROUND
   # WHEN WORKAROUND IS NO LONGER NEEDED, ENABLE THE FOLLOWING LINES:

   # <FH> for 1 .. $lines_offset;
   # $x = tell FH;

   return $x;
}

__END__
